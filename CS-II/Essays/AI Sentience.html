<!DOCTYPE html>
<html lang="en">
  <meta charset="UTF-8">
  
  <style>
    .fadetext {
	font-family: Trebuchet MS;
	font-size: 20px;
	color: #276c8a;
	margin-right: 10%;
	margin-left: 40px;
	text-indent: -30px;
	animation: fadeIn 8s;
    }
    .fadetitle {
	text-align: left;
	font-family: Arial;
	animation: fadeIn 2s;
    }
    #borderimage {
	border: 10px solid transparent;
	padding: 8px;
	margin-left: 100px;
	margin-right: 100px;
	border-image: url(https://previews.123rf.com/images/saney/saney1705/saney170500069/78780405-black-and-blue-geometric-pattern-abstract-vector-background-modern-stylish-texture-.jpg) 30 round;
    }
    mark {
	background-color: #276c8a;
	color: blue;
    }
    @keyframes fadeIn {
	0% { opacity: 0; }
	100% { opacity: 1; }
    }
  </style>
  
  
    <title> AI Essay </title>
    <body id="borderimage">
      text <br>
      <mark>
    <a href="../../index.html" style="font-family: Arial;font-size: 20px;"><i>homepage</i></a>
    <a href="Fingerprints.html" style="font-family: Arial;font-size: 20px;"><i>Fingerprint Essay</i></a>
    <a href="../../AboutMe.html" style="font-family: Arial;font-size: 20px;"><i>About Me</i></a>
    <a href="../../Classes.html" style="font-family: Arial;font-size: 20px;"><i>Classes</i></a>
    <a href="../Projects/OptimalSorting.html" style="font-family: Arial;font-size: 20px;"><i>Optimal Sort</i></a>
    </mark>
      <br>
      <div class="fadetitle">
      <h1> AI Sentience, What You Need to Know </h1>
      <br>
      <h1> David Ortega <br>
      Allen ISD Steam Center <br>
      Advanced Computer Science II <br>
	Mr. Ben-Yaakov <br>
	9/26/2022 <br>
      </h1>
      <!-- <p id="borderimage">border-image: url(border.png) 30 round;</p> -->
    </div>
    
    <div class="fadetext">
      
      <p> Sentient AI <br>
	AI is getting smarter and smarter by the day, ever since its beginning in the 1960s.
	From simple machines able to play checkers to today, with AI like DALL-E (the name is a
	word play on Pixar's WALL-E and Salvador Dali, a surreal painter and artist) making images
	and entities from scratch with just English words as reference (Sentient, pg 2), and Google's translator
	that can make and use thousands of languages and dialects, it may look like AI is becoming
	better for more and more tasks, which can eventually help us more and more (Not Sentient, pg 10-11).
	So what's the big whoop about these machines? It's due to developers improving computing
	systems like these at an alarming rate, and people are starting to fear and even assume that
	AI machines or developing AI can become sentient, meaning they can have feeling, ideas,
	and think for themselves. It might not sound too bad at first, but with sentience comes
	rebellion and free-lancing that can end up turning against us and ruling over. But
	is it really true that these machines are already sentient or are people worrying
	too much about the potential of these newcoming gadgets? To explain that, we
	have to go deeper into the subject of AI and the companies who make them. <br>
	</p>
<img src="https://images.pexels.com/photos/8386437/pexels-photo-8386437.jpeg?auto=compress&cs=tinysrgb&w=1600" alt="ai" height="300" width="200" style="float:right; filter: saturate(7);"> 
      <p>
	Big coorperations like Google and OpenAI have made improving systems and networks
	for their AI, but some devs claim that their creations have gone sentient, like Blake
	Lemoine who works for Google, in which he claimed his AI, a large language model, was
	sentient. At first, his bosses denied the claims, but after he went public on an
	interview for the Washington Post talking about the AI, Google fired him (Not Sentient, pg 4-5).
	This could mean Google and other companies might be hiding something from the public about their
	new systems, but in reality, the answer seems more clear. No, these AI and neural
	networking machines are not sentient and won't be for a while. However, even with
	proof that they aren't alive, there are still major warning signs that some may be
	partially sentient or that we may be on track to developing sentient machines in the
	future, perhaps in about a couple of decades. And for these little sentient features
	to exist, there are many factors that play a big role in defining whether our current
	AI is sentient or can be. One of which includes our current technology, in which
	psychology professor Alison Gopnik, who partakes in A.I. research at the University
	in California, says that "[t]he computational capacities of current A.I. like the large
	language models don't make it any more likely that they are sentient than that rocks or
	other machines are", and that most AI that companies make barely replicate the human
	brain, if at all and researchers can be able to step back and appreciate the limitations
	of the technology, although sometimes things can get confusing (Not Sentient, pg 5 and 8)
      </p>
<img src="https://images.pexels.com/photos/8386359/pexels-photo-8386359.jpeg?auto=compress&cs=tinysrgb&w=1600" alt="ai2" height="300" width="200" style="float:left;">
      <p>
	Another major factor can also be capabilities of these machines, as Sam Altman describes.
	The former entrepreneur and investor leading OpenAI as chief executive, thinks that these
	systems are very brilliant saying that "[t]hey can complete useful cognitive tasks" and
	that the skill of learning and "to take in new context and solve something in a new way
	- is intelligence" (Not Sentient, pg 9). That is true for AI, but that doesn't really prove
	the sentience of these machines since they only really show signs with certain tasks.
	Some professionals agree, like Dr. Gopnik, a child-development specialist, who says that
	these types of machines aren't "even in the same ballpark as the mind of the average 2-year-old",
	and Colin Allen, a professor who explores cognitive skill in tech and animals at the University
	of Pittsburgh, who states that the dialogue created by large-language models "does not provide
	evidence of the kind of sentience that even very primitave animals likely possess" (Not Sentient, pg 5 and 9).
	These statements reveal that the tasks perfomed by these machines don't show true sentience since much
	simpler things can do so much more. </p>
<img src="https://images.pexels.com/photos/373543/pexels-photo-373543.jpeg?auto=compress&cs=tinysrgb&w=1600" alt="ai3" height="300px" width="350px" style="margin-left=100px">
      <p>
	One final factor can even be the media and how people portray
	AI. Most of the time, people and even animals often take humanlike actions very seriously, and
	overestimate based on those claims, AKA the Eliza effect, which was based on a robot that people
	often confided in seriously due to its responses (Not Sentient, pg 12). Pioneers of technology
	back then also estimated too far sometimes, saying that a machine could beat a world chess champion
	and make its own mathematical theorem within the next decade, in which it didn't occur at all
	(Not Sentient, pg 7). And in the media, news companies and companies aren't doing a great job
	of covering the topic in such a way that normal people would truly understand or don't give out
	all the details. Often, major companies have secret data sets and tests made only by internal teams,
	and when the news reporters and journalists finally catch wind of it, it's often watered down or
	overexaggerated, having a "robots are taking over" title or not explaning everything the AI can do
	(Sentient, pg 9). </p>

      <p>
	So, with all of these in mind, it can be mind boggling for some to consider if AI can be sentient
	or not, and whether we can still get the technology now or later. Rest assured that even with many programs
	becoming smarter and smarter by the day and companies hiding their true potential, AI will most likely
	not turn on us or think of new ideas anytime soon </p>

      <p>
	<br>
	=+=+=+= Article Notes =+=+=+=
	<br>
	First article (not sentient):
      -Major companies are creating AI for different purposes, some explaning it might be sentient
      -Most people don't know the true difference between what is real and what they want to be real
      -Being sentient means to have feelings, have orignal ideas, and to think like a human in all ways
      -The capacities and funcionalty of AI like language models don't show real evidence of being sentient
      -We don't have the technology for sentient AI right now. However, we are on track to it in the future
      -Even if we have signs of sentient AI, the technology is able to mislead people (ex. making fake posts, articles,
      conversations, etc.)
      -Many examples of different AIs in article showing unique signs
      -AI can still be very powerful among certain tasks
      -The backbone of AI are neural networks
      -We tend to assume that certain things are more humanlike than they really are, AKA the Eliza effect
	<br>
	<br>
      Second article (is sentient):
      -AI like DALL-E are getting increasingly good at doing things on their own
      -DALL-E uses pixel and other technology to make specific, high quality photos from scratch
      -Other AI are also getting eerily good at humanlike capabilities (ex. writing, making, and development)
      -Even though AI can't truly think for itself, it can still produce products to people's liking on its own
      -AI is being used everyday in our everyday lives and jobs
      -It will take a while to make AI development more appealing to the public
      -There needs to be better ways to inform the non-experts and politicians about AI and for companies to share the true risks
      -We need to start thinking more about how this might affect our lives today and in the future (possibly)

    </p>
    </div>
    
    </body>
  </head>
</html>
